{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib2 as pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=pathlib.Path.cwd()\n",
    "datapath=cwd.joinpath('data')\n",
    "datawreviewsfile=datapath.joinpath('processed/innerJoinData.csv')\n",
    "dataworeviewsfile=datapath.joinpath('raw/collaborative_book_metadata_with_genredummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf=pd.read_csv(datawreviewsfile,sep=';')\n",
    "fulldatadf=pd.read_csv(dataworeviewsfile,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>image_url</th>\n",
       "      <th>url</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>description</th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>book_id_mapping</th>\n",
       "      <th>...</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historicalfiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>nonfiction</th>\n",
       "      <th>paranormal</th>\n",
       "      <th>poetry</th>\n",
       "      <th>romance</th>\n",
       "      <th>thriller</th>\n",
       "      <th>youngadult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5899779</td>\n",
       "      <td>Pride and Prejudice and Zombies Pride and Prej...</td>\n",
       "      <td>https://images.gr-assets.com/books/1320449653m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/5899779-pr...</td>\n",
       "      <td>320</td>\n",
       "      <td>105537</td>\n",
       "      <td>The New York Times Best Seller is now a major ...</td>\n",
       "      <td>['fantasy', 'paranormal', 'romance', 'fiction'...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>808</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>872333</td>\n",
       "      <td>Blue Bloods Blue Bloods 1</td>\n",
       "      <td>https://images.gr-assets.com/books/1322281515m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/872333.Blu...</td>\n",
       "      <td>302</td>\n",
       "      <td>117633</td>\n",
       "      <td>When the Mayflower set sail in 1620, it carrie...</td>\n",
       "      <td>['youngadult', 'fantasy', 'paranormal', 'roman...</td>\n",
       "      <td>Melissa de la Cruz</td>\n",
       "      <td>217</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15507958</td>\n",
       "      <td>Me Before You Me Before You 1</td>\n",
       "      <td>https://images.gr-assets.com/books/1357108762m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/15507958-m...</td>\n",
       "      <td>369</td>\n",
       "      <td>609327</td>\n",
       "      <td>Louisa Clark is an ordinary young woman living...</td>\n",
       "      <td>['romance', 'fiction']</td>\n",
       "      <td>Jojo Moyes</td>\n",
       "      <td>385</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66559</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>https://images.gr-assets.com/books/1423241485m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/66559.Shar...</td>\n",
       "      <td>254</td>\n",
       "      <td>208394</td>\n",
       "      <td>Fresh from a brief stay at a psych hospital, r...</td>\n",
       "      <td>['mystery', 'thriller', 'crime', 'fiction']</td>\n",
       "      <td>Gillian Flynn</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7235533</td>\n",
       "      <td>The Way of Kings The Stormlight Archive 1</td>\n",
       "      <td>https://images.gr-assets.com/books/1507307887m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7235533-th...</td>\n",
       "      <td>1007</td>\n",
       "      <td>151473</td>\n",
       "      <td>Speak again the ancient oaths,\\nLife before de...</td>\n",
       "      <td>['fantasy', 'paranormal', 'fiction']</td>\n",
       "      <td>Brandon Sanderson</td>\n",
       "      <td>873</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                                              title  \\\n",
       "0   5899779  Pride and Prejudice and Zombies Pride and Prej...   \n",
       "1    872333                          Blue Bloods Blue Bloods 1   \n",
       "2  15507958                      Me Before You Me Before You 1   \n",
       "3     66559                                      Sharp Objects   \n",
       "4   7235533          The Way of Kings The Stormlight Archive 1   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1320449653m...   \n",
       "1  https://images.gr-assets.com/books/1322281515m...   \n",
       "2  https://images.gr-assets.com/books/1357108762m...   \n",
       "3  https://images.gr-assets.com/books/1423241485m...   \n",
       "4  https://images.gr-assets.com/books/1507307887m...   \n",
       "\n",
       "                                                 url  num_pages  \\\n",
       "0  https://www.goodreads.com/book/show/5899779-pr...        320   \n",
       "1  https://www.goodreads.com/book/show/872333.Blu...        302   \n",
       "2  https://www.goodreads.com/book/show/15507958-m...        369   \n",
       "3  https://www.goodreads.com/book/show/66559.Shar...        254   \n",
       "4  https://www.goodreads.com/book/show/7235533-th...       1007   \n",
       "\n",
       "   ratings_count                                        description  \\\n",
       "0         105537  The New York Times Best Seller is now a major ...   \n",
       "1         117633  When the Mayflower set sail in 1620, it carrie...   \n",
       "2         609327  Louisa Clark is an ordinary young woman living...   \n",
       "3         208394  Fresh from a brief stay at a psych hospital, r...   \n",
       "4         151473  Speak again the ancient oaths,\\nLife before de...   \n",
       "\n",
       "                                               genre                name  \\\n",
       "0  ['fantasy', 'paranormal', 'romance', 'fiction'...         Jane Austen   \n",
       "1  ['youngadult', 'fantasy', 'paranormal', 'roman...  Melissa de la Cruz   \n",
       "2                             ['romance', 'fiction']          Jojo Moyes   \n",
       "3        ['mystery', 'thriller', 'crime', 'fiction']       Gillian Flynn   \n",
       "4               ['fantasy', 'paranormal', 'fiction']   Brandon Sanderson   \n",
       "\n",
       "   book_id_mapping  ...  graphic  historicalfiction  history  mystery  \\\n",
       "0              808  ...        0                  1        1        1   \n",
       "1              217  ...        0                  0        0        1   \n",
       "2              385  ...        0                  0        0        0   \n",
       "3              192  ...        0                  0        0        1   \n",
       "4              873  ...        0                  0        0        0   \n",
       "\n",
       "   nonfiction  paranormal  poetry  romance  thriller  youngadult  \n",
       "0           0           1       0        1         1           1  \n",
       "1           0           1       0        1         1           1  \n",
       "2           0           0       0        1         0           0  \n",
       "3           0           0       0        0         1           0  \n",
       "4           0           1       0        0         0           0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldatadf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group books via genres\n",
    "- vectorize genre-list, countvectorizer vs tfidf (pos: fiction genre very prevalent, thus less relevant in distinction of books)\n",
    "    - cluster genres (uneven size clusters? not very distinct? fuzzy clustering instead?)\n",
    "    - topic modeling (lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group books via blurb content\n",
    "- vectorize, topics via topic modeling\n",
    "-  tfidf -> lda\n",
    "    - evaluate via topic coherence\n",
    "- https://github.com/kapadias/medium-articles/blob/master/natural-language-processing/topic-modeling/Evaluate%20Topic%20Models.ipynb\n",
    "- https://medium.com/@walter_sperat/using-optuna-with-sklearn-the-right-way-part-1-6b4ad0ab2451\n",
    "- https://learn-scikit.oneoffcoder.com/optuna.html\n",
    "- https://learn-scikit.oneoffcoder.com/gensim.html\n",
    "- https://stackoverflow.com/questions/60613532/how-do-i-calculate-the-coherence-score-of-an-sklearn-lda-model\n",
    "-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import Trial, create_study\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "# import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics import make_scorer\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "randomstate=313\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### description\n",
    "pipeline: tfidf, lda\n",
    "\n",
    "- no crossvalidation in optuna when evaluating topics based on gensim coherence c_v, as scikitlearns make_scorer() only works with y_true to evaluate agains (only supervised clustering), this is not ideal, different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = Pipeline([('tfidf',TfidfVectorizer()),('lda',LatentDirichletAllocation())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topiccoherencescorer(pipe,X):\n",
    "    n_top_words = 15 #higher value for higher coherence, i.e. more word to make connections for coherence\n",
    "    topics=pipe.named_steps.lda.components_\n",
    "    texts=[[word for word in doc.split()] for doc in X]\n",
    "    dictionary=corpora.Dictionary(texts)\n",
    "    corpus=[dictionary.doc2bow(text) for text in texts]\n",
    "    feature_names = [dictionary[i] for i in range(len(dictionary))]\n",
    "    top_words = []\n",
    "    for topic in topics:\n",
    "        top_words.append([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "    cm = CoherenceModel(topics=top_words, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    return cm.get_coherence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inst_tfidf(trial:Trial)->TfidfVectorizer:\n",
    "    params={\n",
    "        'norm':trial.suggest_categorical('norm',['l1','l2', None]),\n",
    "        'smooth_idf':trial.suggest_categorical('smooth_idf',[True,False]),\n",
    "        'sublinear_tf':trial.suggest_categorical('sublinear_tf',[True,False]),\n",
    "        'stop_words':trial.suggest_categorical('stop_words',[None,'english',list(STOPWORDS)]),\n",
    "        # 'max_df':trial.suggest_float('max_df',0,1),\n",
    "        # 'min_df':trial.suggest_float('min_df',0,1),\n",
    "        'max_features':trial.suggest_categorical('max_features',[None,300,150,100,50]) #can't use int, because of None\n",
    "        }\n",
    "    return TfidfVectorizer(**params)\n",
    "def inst_lda(trial:Trial)->LatentDirichletAllocation:\n",
    "    params={\n",
    "        'learning_method':trial.suggest_categorical('learning_method',['batch','online']),\n",
    "        'learning_decay':trial.suggest_float('learning_decay',0.5,0.9),\n",
    "        'learning_offset':trial.suggest_float('learning_offset',2,20),\n",
    "        'max_iter':trial.suggest_int('max_iter',5,20),\n",
    "        'batch_size':trial.suggest_int('batch_size',5,128),\n",
    "        'max_doc_update_iter':trial.suggest_int('max_doc_update_iter',0.001,0.1),\n",
    "        'n_jobs':-1,\n",
    "        'random_state':randomstate\n",
    "    }\n",
    "    return LatentDirichletAllocation(**params)\n",
    "def inst_pipeTFLDA(trial:Trial)->Pipeline:\n",
    "    pipeline=Pipeline([\n",
    "        ('tfidf',inst_tfidf(trial)),\n",
    "        ('lda',inst_lda(trial))\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "def objective(trial:Trial,x:pd.DataFrame)->float:\n",
    "    model=inst_pipeTFLDA(trial)\n",
    "    \n",
    "    pipe=model.fit(x)\n",
    "    score=topiccoherencescorer(pipe,x)\n",
    "    \n",
    "    \n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 19:54:01,221] A new study created in RDB with name: description_tfidflda_study\n"
     ]
    }
   ],
   "source": [
    "study=create_study(study_name='description_tfidflda_study',direction='maximize',storage='sqlite:///description_tfidflda_study.db',load_if_exists=True) #TPESampler used as default, no pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad358a26f454ccf97c549fe33e0ebfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ['her', 'nevertheless', 'itself', 'so', 'or', 'will', 'still', 'take', 'indeed', 'could', 'latterly', 'whether', 'third', 'really', 'con', 'ours', 'somewhere', 'system', 'what', 'why', 'de', 'been', 'make', 'others', 'latter', 'that', 'mostly', 'don', 'becoming', 'nor', 're', 'bottom', 'off', 'beforehand', 'against', 'whereas', 'part', 'towards', 'throughout', 'might', 'too', 'sometime', 'perhaps', 'thereafter', 'and', 'often', 'very', 'moreover', 'on', 'am', 'ie', 'interest', 'with', 'other', 'nowhere', 'eight', 'rather', 'however', 'hereafter', 'should', 'no', 'say', 'the', 'forty', 'were', 'eg', 'full', 'either', 'upon', 'ten', 'afterwards', 'nine', 'your', 'since', 'around', 'for', 'well', 'just', 'these', 'using', 'while', 'therein', 'you', 'hers', 'everyone', 'several', 'herein', 'amongst', 'detail', 'get', 'thence', 'themselves', 'herself', 'are', 'one', 'here', 'became', 'via', 'seems', 'six', 'own', 'further', 'none', 'below', 'seem', 'sincere', 'anywhere', 'toward', 'mine', 'be', 'some', 'they', 'she', 'now', 'than', 'thereby', 'three', 'cry', 'wherever', 'yourselves', 'regarding', 'kg', 'whither', 'yet', 'until', 'yourself', 'before', 'into', 'out', 'find', 'everything', 'has', 'thin', 'anyhow', 'not', 'without', 'only', 'an', 'fifty', 'put', 'there', 'anyone', 'didn', 'hereby', 'wherein', 'whole', 'all', 'under', 'becomes', 'former', 'please', 'of', 'between', 'to', 'km', 'above', 'both', 'amoungst', 'how', 'in', 'this', 'whenever', 'eleven', 'side', 'must', 'much', 'almost', 'whoever', 'seeming', 'where', 'then', 'whose', 'due', 'within', 'thru', 'every', 'being', 'have', 'ourselves', 'at', 'somehow', 'thus', 'those', 'by', 'name', 'go', 'was', 'among', 'five', 'whence', 'elsewhere', 'twenty', 'across', 'anyway', 'because', 'nobody', 'therefore', 'next', 'become', 'i', 'top', 'couldnt', 'call', 'keep', 'hasnt', 'quite', 'us', 'cant', 'hence', 'ltd', 'can', 'me', 'thereupon', 'front', 'less', 'also', 'move', 'always', 'a', 'had', 'otherwise', 'serious', 'him', 'any', 'over', 'namely', 'used', 'once', 'beyond', 'such', 'them', 'least', 'never', 'down', 'four', 'nothing', 'would', 'about', 'bill', 'most', 'else', 'describe', 'up', 'from', 'fill', 'etc', 'through', 'hereupon', 'his', 'noone', 'enough', 'is', 'back', 'its', 'sixty', 'various', 'everywhere', 'but', 'two', 'inc', 'hundred', 'we', 'if', 'someone', 'give', 'thick', 'fire', 'each', 'along', 'more', 'he', 'whereafter', 'twelve', 'together', 'first', 'again', 'besides', 'yours', 'during', 'co', 'our', 'ever', 'though', 'whereupon', 'himself', 'few', 'something', 'when', 'it', 'behind', 'doing', 'who', 'seemed', 'formerly', 'except', 'alone', 'meanwhile', 'done', 'see', 'after', 'their', 'already', 'myself', 'empty', 'neither', 'does', 'per', 'whom', 'did', 'doesn', 'although', 'show', 'another', 'my', 'which', 'whereby', 'last', 'anything', 'computer', 'do', 'onto', 'mill', 'cannot', 'whatever', 'found', 'beside', 'sometimes', 'amount', 'as', 'same', 'un', 'may', 'many', 'fifteen', 'even', 'unless', 'made'] which is of type list.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2024-08-27 19:54:03,444] Trial 1 failed with parameters: {'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': False, 'stop_words': None, 'max_df': 0.3607755861867905, 'min_df': 0.8797550353659859, 'max_features': 150, 'learning_method': 'online', 'learning_decay': 0.8028828039153562, 'learning_offset': 19.97501518218227, 'max_iter': 20, 'batch_size': 98, 'max_doc_update_iter': 0} because of the following error: ValueError('max_df corresponds to < documents than min_df').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\968308381.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\3378151726.py\", line 34, in objective\n",
      "    pipe=model.fit(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1399, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "[W 2024-08-27 19:54:03,469] Trial 1 failed with value None.\n",
      "[W 2024-08-27 19:54:03,696] Trial 8 failed with parameters: {'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': False, 'stop_words': 'english', 'max_df': 0.09097914078729197, 'min_df': 0.3538564467715676, 'max_features': 100, 'learning_method': 'online', 'learning_decay': 0.8881967037420948, 'learning_offset': 16.3537003889463, 'max_iter': 17, 'batch_size': 104, 'max_doc_update_iter': 0} because of the following error: ValueError('max_df corresponds to < documents than min_df').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\968308381.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\3378151726.py\", line 34, in objective\n",
      "    pipe=model.fit(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1399, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "[W 2024-08-27 19:54:03,702] Trial 8 failed with value None.\n",
      "[W 2024-08-27 19:54:03,974] Trial 5 failed with parameters: {'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'stop_words': 'english', 'max_df': 0.8106739266887129, 'min_df': 0.8921314057566662, 'max_features': 50, 'learning_method': 'online', 'learning_decay': 0.722914864359187, 'learning_offset': 14.007110630276115, 'max_iter': 8, 'batch_size': 127, 'max_doc_update_iter': 0} because of the following error: ValueError('max_df corresponds to < documents than min_df').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\968308381.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\3378151726.py\", line 34, in objective\n",
      "    pipe=model.fit(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1399, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "[W 2024-08-27 19:54:03,992] Trial 5 failed with value None.\n",
      "[W 2024-08-27 19:54:04,173] Trial 11 failed with parameters: {'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': False, 'stop_words': ['her', 'nevertheless', 'itself', 'so', 'or', 'will', 'still', 'take', 'indeed', 'could', 'latterly', 'whether', 'third', 'really', 'con', 'ours', 'somewhere', 'system', 'what', 'why', 'de', 'been', 'make', 'others', 'latter', 'that', 'mostly', 'don', 'becoming', 'nor', 're', 'bottom', 'off', 'beforehand', 'against', 'whereas', 'part', 'towards', 'throughout', 'might', 'too', 'sometime', 'perhaps', 'thereafter', 'and', 'often', 'very', 'moreover', 'on', 'am', 'ie', 'interest', 'with', 'other', 'nowhere', 'eight', 'rather', 'however', 'hereafter', 'should', 'no', 'say', 'the', 'forty', 'were', 'eg', 'full', 'either', 'upon', 'ten', 'afterwards', 'nine', 'your', 'since', 'around', 'for', 'well', 'just', 'these', 'using', 'while', 'therein', 'you', 'hers', 'everyone', 'several', 'herein', 'amongst', 'detail', 'get', 'thence', 'themselves', 'herself', 'are', 'one', 'here', 'became', 'via', 'seems', 'six', 'own', 'further', 'none', 'below', 'seem', 'sincere', 'anywhere', 'toward', 'mine', 'be', 'some', 'they', 'she', 'now', 'than', 'thereby', 'three', 'cry', 'wherever', 'yourselves', 'regarding', 'kg', 'whither', 'yet', 'until', 'yourself', 'before', 'into', 'out', 'find', 'everything', 'has', 'thin', 'anyhow', 'not', 'without', 'only', 'an', 'fifty', 'put', 'there', 'anyone', 'didn', 'hereby', 'wherein', 'whole', 'all', 'under', 'becomes', 'former', 'please', 'of', 'between', 'to', 'km', 'above', 'both', 'amoungst', 'how', 'in', 'this', 'whenever', 'eleven', 'side', 'must', 'much', 'almost', 'whoever', 'seeming', 'where', 'then', 'whose', 'due', 'within', 'thru', 'every', 'being', 'have', 'ourselves', 'at', 'somehow', 'thus', 'those', 'by', 'name', 'go', 'was', 'among', 'five', 'whence', 'elsewhere', 'twenty', 'across', 'anyway', 'because', 'nobody', 'therefore', 'next', 'become', 'i', 'top', 'couldnt', 'call', 'keep', 'hasnt', 'quite', 'us', 'cant', 'hence', 'ltd', 'can', 'me', 'thereupon', 'front', 'less', 'also', 'move', 'always', 'a', 'had', 'otherwise', 'serious', 'him', 'any', 'over', 'namely', 'used', 'once', 'beyond', 'such', 'them', 'least', 'never', 'down', 'four', 'nothing', 'would', 'about', 'bill', 'most', 'else', 'describe', 'up', 'from', 'fill', 'etc', 'through', 'hereupon', 'his', 'noone', 'enough', 'is', 'back', 'its', 'sixty', 'various', 'everywhere', 'but', 'two', 'inc', 'hundred', 'we', 'if', 'someone', 'give', 'thick', 'fire', 'each', 'along', 'more', 'he', 'whereafter', 'twelve', 'together', 'first', 'again', 'besides', 'yours', 'during', 'co', 'our', 'ever', 'though', 'whereupon', 'himself', 'few', 'something', 'when', 'it', 'behind', 'doing', 'who', 'seemed', 'formerly', 'except', 'alone', 'meanwhile', 'done', 'see', 'after', 'their', 'already', 'myself', 'empty', 'neither', 'does', 'per', 'whom', 'did', 'doesn', 'although', 'show', 'another', 'my', 'which', 'whereby', 'last', 'anything', 'computer', 'do', 'onto', 'mill', 'cannot', 'whatever', 'found', 'beside', 'sometimes', 'amount', 'as', 'same', 'un', 'may', 'many', 'fifteen', 'even', 'unless', 'made'], 'max_df': 0.7056874520978509, 'min_df': 0.8737302307405312, 'max_features': 150, 'learning_method': 'batch', 'learning_decay': 0.8892021141279729, 'learning_offset': 6.596526086822519, 'max_iter': 13, 'batch_size': 86, 'max_doc_update_iter': 0} because of the following error: ValueError('max_df corresponds to < documents than min_df').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\968308381.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\3378151726.py\", line 34, in objective\n",
      "    pipe=model.fit(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1399, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "[W 2024-08-27 19:54:04,184] Trial 11 failed with value None.\n",
      "[W 2024-08-27 19:54:04,463] Trial 0 failed with parameters: {'norm': 'l1', 'smooth_idf': True, 'sublinear_tf': True, 'stop_words': ['her', 'nevertheless', 'itself', 'so', 'or', 'will', 'still', 'take', 'indeed', 'could', 'latterly', 'whether', 'third', 'really', 'con', 'ours', 'somewhere', 'system', 'what', 'why', 'de', 'been', 'make', 'others', 'latter', 'that', 'mostly', 'don', 'becoming', 'nor', 're', 'bottom', 'off', 'beforehand', 'against', 'whereas', 'part', 'towards', 'throughout', 'might', 'too', 'sometime', 'perhaps', 'thereafter', 'and', 'often', 'very', 'moreover', 'on', 'am', 'ie', 'interest', 'with', 'other', 'nowhere', 'eight', 'rather', 'however', 'hereafter', 'should', 'no', 'say', 'the', 'forty', 'were', 'eg', 'full', 'either', 'upon', 'ten', 'afterwards', 'nine', 'your', 'since', 'around', 'for', 'well', 'just', 'these', 'using', 'while', 'therein', 'you', 'hers', 'everyone', 'several', 'herein', 'amongst', 'detail', 'get', 'thence', 'themselves', 'herself', 'are', 'one', 'here', 'became', 'via', 'seems', 'six', 'own', 'further', 'none', 'below', 'seem', 'sincere', 'anywhere', 'toward', 'mine', 'be', 'some', 'they', 'she', 'now', 'than', 'thereby', 'three', 'cry', 'wherever', 'yourselves', 'regarding', 'kg', 'whither', 'yet', 'until', 'yourself', 'before', 'into', 'out', 'find', 'everything', 'has', 'thin', 'anyhow', 'not', 'without', 'only', 'an', 'fifty', 'put', 'there', 'anyone', 'didn', 'hereby', 'wherein', 'whole', 'all', 'under', 'becomes', 'former', 'please', 'of', 'between', 'to', 'km', 'above', 'both', 'amoungst', 'how', 'in', 'this', 'whenever', 'eleven', 'side', 'must', 'much', 'almost', 'whoever', 'seeming', 'where', 'then', 'whose', 'due', 'within', 'thru', 'every', 'being', 'have', 'ourselves', 'at', 'somehow', 'thus', 'those', 'by', 'name', 'go', 'was', 'among', 'five', 'whence', 'elsewhere', 'twenty', 'across', 'anyway', 'because', 'nobody', 'therefore', 'next', 'become', 'i', 'top', 'couldnt', 'call', 'keep', 'hasnt', 'quite', 'us', 'cant', 'hence', 'ltd', 'can', 'me', 'thereupon', 'front', 'less', 'also', 'move', 'always', 'a', 'had', 'otherwise', 'serious', 'him', 'any', 'over', 'namely', 'used', 'once', 'beyond', 'such', 'them', 'least', 'never', 'down', 'four', 'nothing', 'would', 'about', 'bill', 'most', 'else', 'describe', 'up', 'from', 'fill', 'etc', 'through', 'hereupon', 'his', 'noone', 'enough', 'is', 'back', 'its', 'sixty', 'various', 'everywhere', 'but', 'two', 'inc', 'hundred', 'we', 'if', 'someone', 'give', 'thick', 'fire', 'each', 'along', 'more', 'he', 'whereafter', 'twelve', 'together', 'first', 'again', 'besides', 'yours', 'during', 'co', 'our', 'ever', 'though', 'whereupon', 'himself', 'few', 'something', 'when', 'it', 'behind', 'doing', 'who', 'seemed', 'formerly', 'except', 'alone', 'meanwhile', 'done', 'see', 'after', 'their', 'already', 'myself', 'empty', 'neither', 'does', 'per', 'whom', 'did', 'doesn', 'although', 'show', 'another', 'my', 'which', 'whereby', 'last', 'anything', 'computer', 'do', 'onto', 'mill', 'cannot', 'whatever', 'found', 'beside', 'sometimes', 'amount', 'as', 'same', 'un', 'may', 'many', 'fifteen', 'even', 'unless', 'made'], 'max_df': 0.7496355514607296, 'min_df': 0.7778337471888208, 'max_features': 50, 'learning_method': 'batch', 'learning_decay': 0.7628681439096059, 'learning_offset': 2.3592584176387996, 'max_iter': 12, 'batch_size': 26, 'max_doc_update_iter': 0} because of the following error: ValueError('max_df corresponds to < documents than min_df').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\968308381.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\3378151726.py\", line 34, in objective\n",
      "    pipe=model.fit(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1399, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "[W 2024-08-27 19:54:04,476] Trial 0 failed with value None.\n",
      "[W 2024-08-27 19:54:04,687] Trial 3 failed with parameters: {'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': True, 'stop_words': ['her', 'nevertheless', 'itself', 'so', 'or', 'will', 'still', 'take', 'indeed', 'could', 'latterly', 'whether', 'third', 'really', 'con', 'ours', 'somewhere', 'system', 'what', 'why', 'de', 'been', 'make', 'others', 'latter', 'that', 'mostly', 'don', 'becoming', 'nor', 're', 'bottom', 'off', 'beforehand', 'against', 'whereas', 'part', 'towards', 'throughout', 'might', 'too', 'sometime', 'perhaps', 'thereafter', 'and', 'often', 'very', 'moreover', 'on', 'am', 'ie', 'interest', 'with', 'other', 'nowhere', 'eight', 'rather', 'however', 'hereafter', 'should', 'no', 'say', 'the', 'forty', 'were', 'eg', 'full', 'either', 'upon', 'ten', 'afterwards', 'nine', 'your', 'since', 'around', 'for', 'well', 'just', 'these', 'using', 'while', 'therein', 'you', 'hers', 'everyone', 'several', 'herein', 'amongst', 'detail', 'get', 'thence', 'themselves', 'herself', 'are', 'one', 'here', 'became', 'via', 'seems', 'six', 'own', 'further', 'none', 'below', 'seem', 'sincere', 'anywhere', 'toward', 'mine', 'be', 'some', 'they', 'she', 'now', 'than', 'thereby', 'three', 'cry', 'wherever', 'yourselves', 'regarding', 'kg', 'whither', 'yet', 'until', 'yourself', 'before', 'into', 'out', 'find', 'everything', 'has', 'thin', 'anyhow', 'not', 'without', 'only', 'an', 'fifty', 'put', 'there', 'anyone', 'didn', 'hereby', 'wherein', 'whole', 'all', 'under', 'becomes', 'former', 'please', 'of', 'between', 'to', 'km', 'above', 'both', 'amoungst', 'how', 'in', 'this', 'whenever', 'eleven', 'side', 'must', 'much', 'almost', 'whoever', 'seeming', 'where', 'then', 'whose', 'due', 'within', 'thru', 'every', 'being', 'have', 'ourselves', 'at', 'somehow', 'thus', 'those', 'by', 'name', 'go', 'was', 'among', 'five', 'whence', 'elsewhere', 'twenty', 'across', 'anyway', 'because', 'nobody', 'therefore', 'next', 'become', 'i', 'top', 'couldnt', 'call', 'keep', 'hasnt', 'quite', 'us', 'cant', 'hence', 'ltd', 'can', 'me', 'thereupon', 'front', 'less', 'also', 'move', 'always', 'a', 'had', 'otherwise', 'serious', 'him', 'any', 'over', 'namely', 'used', 'once', 'beyond', 'such', 'them', 'least', 'never', 'down', 'four', 'nothing', 'would', 'about', 'bill', 'most', 'else', 'describe', 'up', 'from', 'fill', 'etc', 'through', 'hereupon', 'his', 'noone', 'enough', 'is', 'back', 'its', 'sixty', 'various', 'everywhere', 'but', 'two', 'inc', 'hundred', 'we', 'if', 'someone', 'give', 'thick', 'fire', 'each', 'along', 'more', 'he', 'whereafter', 'twelve', 'together', 'first', 'again', 'besides', 'yours', 'during', 'co', 'our', 'ever', 'though', 'whereupon', 'himself', 'few', 'something', 'when', 'it', 'behind', 'doing', 'who', 'seemed', 'formerly', 'except', 'alone', 'meanwhile', 'done', 'see', 'after', 'their', 'already', 'myself', 'empty', 'neither', 'does', 'per', 'whom', 'did', 'doesn', 'although', 'show', 'another', 'my', 'which', 'whereby', 'last', 'anything', 'computer', 'do', 'onto', 'mill', 'cannot', 'whatever', 'found', 'beside', 'sometimes', 'amount', 'as', 'same', 'un', 'may', 'many', 'fifteen', 'even', 'unless', 'made'], 'max_df': 0.7761270928802569, 'min_df': 0.6415170143194602, 'max_features': None, 'learning_method': 'batch', 'learning_decay': 0.7607277447434029, 'learning_offset': 16.063218229384976, 'max_iter': 7, 'batch_size': 115, 'max_doc_update_iter': 0} because of the following error: ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\968308381.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\3378151726.py\", line 34, in objective\n",
      "    pipe=model.fit(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1402, in fit_transform\n",
      "    X, self.stop_words_ = self._limit_features(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1254, in _limit_features\n",
      "    raise ValueError(\n",
      "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
      "[W 2024-08-27 19:54:04,691] Trial 3 failed with value None.\n",
      "[W 2024-08-27 19:54:04,766] Trial 14 failed with parameters: {'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': True, 'stop_words': ['her', 'nevertheless', 'itself', 'so', 'or', 'will', 'still', 'take', 'indeed', 'could', 'latterly', 'whether', 'third', 'really', 'con', 'ours', 'somewhere', 'system', 'what', 'why', 'de', 'been', 'make', 'others', 'latter', 'that', 'mostly', 'don', 'becoming', 'nor', 're', 'bottom', 'off', 'beforehand', 'against', 'whereas', 'part', 'towards', 'throughout', 'might', 'too', 'sometime', 'perhaps', 'thereafter', 'and', 'often', 'very', 'moreover', 'on', 'am', 'ie', 'interest', 'with', 'other', 'nowhere', 'eight', 'rather', 'however', 'hereafter', 'should', 'no', 'say', 'the', 'forty', 'were', 'eg', 'full', 'either', 'upon', 'ten', 'afterwards', 'nine', 'your', 'since', 'around', 'for', 'well', 'just', 'these', 'using', 'while', 'therein', 'you', 'hers', 'everyone', 'several', 'herein', 'amongst', 'detail', 'get', 'thence', 'themselves', 'herself', 'are', 'one', 'here', 'became', 'via', 'seems', 'six', 'own', 'further', 'none', 'below', 'seem', 'sincere', 'anywhere', 'toward', 'mine', 'be', 'some', 'they', 'she', 'now', 'than', 'thereby', 'three', 'cry', 'wherever', 'yourselves', 'regarding', 'kg', 'whither', 'yet', 'until', 'yourself', 'before', 'into', 'out', 'find', 'everything', 'has', 'thin', 'anyhow', 'not', 'without', 'only', 'an', 'fifty', 'put', 'there', 'anyone', 'didn', 'hereby', 'wherein', 'whole', 'all', 'under', 'becomes', 'former', 'please', 'of', 'between', 'to', 'km', 'above', 'both', 'amoungst', 'how', 'in', 'this', 'whenever', 'eleven', 'side', 'must', 'much', 'almost', 'whoever', 'seeming', 'where', 'then', 'whose', 'due', 'within', 'thru', 'every', 'being', 'have', 'ourselves', 'at', 'somehow', 'thus', 'those', 'by', 'name', 'go', 'was', 'among', 'five', 'whence', 'elsewhere', 'twenty', 'across', 'anyway', 'because', 'nobody', 'therefore', 'next', 'become', 'i', 'top', 'couldnt', 'call', 'keep', 'hasnt', 'quite', 'us', 'cant', 'hence', 'ltd', 'can', 'me', 'thereupon', 'front', 'less', 'also', 'move', 'always', 'a', 'had', 'otherwise', 'serious', 'him', 'any', 'over', 'namely', 'used', 'once', 'beyond', 'such', 'them', 'least', 'never', 'down', 'four', 'nothing', 'would', 'about', 'bill', 'most', 'else', 'describe', 'up', 'from', 'fill', 'etc', 'through', 'hereupon', 'his', 'noone', 'enough', 'is', 'back', 'its', 'sixty', 'various', 'everywhere', 'but', 'two', 'inc', 'hundred', 'we', 'if', 'someone', 'give', 'thick', 'fire', 'each', 'along', 'more', 'he', 'whereafter', 'twelve', 'together', 'first', 'again', 'besides', 'yours', 'during', 'co', 'our', 'ever', 'though', 'whereupon', 'himself', 'few', 'something', 'when', 'it', 'behind', 'doing', 'who', 'seemed', 'formerly', 'except', 'alone', 'meanwhile', 'done', 'see', 'after', 'their', 'already', 'myself', 'empty', 'neither', 'does', 'per', 'whom', 'did', 'doesn', 'although', 'show', 'another', 'my', 'which', 'whereby', 'last', 'anything', 'computer', 'do', 'onto', 'mill', 'cannot', 'whatever', 'found', 'beside', 'sometimes', 'amount', 'as', 'same', 'un', 'may', 'many', 'fifteen', 'even', 'unless', 'made'], 'max_df': 0.4522585877840285, 'min_df': 0.8204209010432372, 'max_features': None, 'learning_method': 'online', 'learning_decay': 0.5164356927866789, 'learning_offset': 14.74269526596955, 'max_iter': 10, 'batch_size': 83, 'max_doc_update_iter': 0} because of the following error: ValueError('max_df corresponds to < documents than min_df').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\968308381.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\3378151726.py\", line 34, in objective\n",
      "    pipe=model.fit(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1399, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "[W 2024-08-27 19:54:04,769] Trial 14 failed with value None.\n",
      "[W 2024-08-27 19:54:04,881] Trial 15 failed with parameters: {'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': False, 'stop_words': None, 'max_df': 0.1512803137840678, 'min_df': 0.5789320197720199, 'max_features': 100, 'learning_method': 'online', 'learning_decay': 0.6577364313571674, 'learning_offset': 12.536044608860264, 'max_iter': 5, 'batch_size': 13, 'max_doc_update_iter': 0} because of the following error: ValueError('max_df corresponds to < documents than min_df').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\968308381.py\", line 1, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lekle\\AppData\\Local\\Temp\\ipykernel_8584\\3378151726.py\", line 34, in objective\n",
      "    pipe=model.fit(x)\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 2138, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1399, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "[W 2024-08-27 19:54:04,884] Trial 15 failed with value None.\n",
      "[I 2024-08-27 19:54:31,196] Trial 12 finished with value: 0.5914937865440609 and parameters: {'norm': None, 'smooth_idf': True, 'sublinear_tf': True, 'stop_words': ['her', 'nevertheless', 'itself', 'so', 'or', 'will', 'still', 'take', 'indeed', 'could', 'latterly', 'whether', 'third', 'really', 'con', 'ours', 'somewhere', 'system', 'what', 'why', 'de', 'been', 'make', 'others', 'latter', 'that', 'mostly', 'don', 'becoming', 'nor', 're', 'bottom', 'off', 'beforehand', 'against', 'whereas', 'part', 'towards', 'throughout', 'might', 'too', 'sometime', 'perhaps', 'thereafter', 'and', 'often', 'very', 'moreover', 'on', 'am', 'ie', 'interest', 'with', 'other', 'nowhere', 'eight', 'rather', 'however', 'hereafter', 'should', 'no', 'say', 'the', 'forty', 'were', 'eg', 'full', 'either', 'upon', 'ten', 'afterwards', 'nine', 'your', 'since', 'around', 'for', 'well', 'just', 'these', 'using', 'while', 'therein', 'you', 'hers', 'everyone', 'several', 'herein', 'amongst', 'detail', 'get', 'thence', 'themselves', 'herself', 'are', 'one', 'here', 'became', 'via', 'seems', 'six', 'own', 'further', 'none', 'below', 'seem', 'sincere', 'anywhere', 'toward', 'mine', 'be', 'some', 'they', 'she', 'now', 'than', 'thereby', 'three', 'cry', 'wherever', 'yourselves', 'regarding', 'kg', 'whither', 'yet', 'until', 'yourself', 'before', 'into', 'out', 'find', 'everything', 'has', 'thin', 'anyhow', 'not', 'without', 'only', 'an', 'fifty', 'put', 'there', 'anyone', 'didn', 'hereby', 'wherein', 'whole', 'all', 'under', 'becomes', 'former', 'please', 'of', 'between', 'to', 'km', 'above', 'both', 'amoungst', 'how', 'in', 'this', 'whenever', 'eleven', 'side', 'must', 'much', 'almost', 'whoever', 'seeming', 'where', 'then', 'whose', 'due', 'within', 'thru', 'every', 'being', 'have', 'ourselves', 'at', 'somehow', 'thus', 'those', 'by', 'name', 'go', 'was', 'among', 'five', 'whence', 'elsewhere', 'twenty', 'across', 'anyway', 'because', 'nobody', 'therefore', 'next', 'become', 'i', 'top', 'couldnt', 'call', 'keep', 'hasnt', 'quite', 'us', 'cant', 'hence', 'ltd', 'can', 'me', 'thereupon', 'front', 'less', 'also', 'move', 'always', 'a', 'had', 'otherwise', 'serious', 'him', 'any', 'over', 'namely', 'used', 'once', 'beyond', 'such', 'them', 'least', 'never', 'down', 'four', 'nothing', 'would', 'about', 'bill', 'most', 'else', 'describe', 'up', 'from', 'fill', 'etc', 'through', 'hereupon', 'his', 'noone', 'enough', 'is', 'back', 'its', 'sixty', 'various', 'everywhere', 'but', 'two', 'inc', 'hundred', 'we', 'if', 'someone', 'give', 'thick', 'fire', 'each', 'along', 'more', 'he', 'whereafter', 'twelve', 'together', 'first', 'again', 'besides', 'yours', 'during', 'co', 'our', 'ever', 'though', 'whereupon', 'himself', 'few', 'something', 'when', 'it', 'behind', 'doing', 'who', 'seemed', 'formerly', 'except', 'alone', 'meanwhile', 'done', 'see', 'after', 'their', 'already', 'myself', 'empty', 'neither', 'does', 'per', 'whom', 'did', 'doesn', 'although', 'show', 'another', 'my', 'which', 'whereby', 'last', 'anything', 'computer', 'do', 'onto', 'mill', 'cannot', 'whatever', 'found', 'beside', 'sometimes', 'amount', 'as', 'same', 'un', 'may', 'many', 'fifteen', 'even', 'unless', 'made'], 'max_df': 0.8265190042610226, 'min_df': 0.09021402738643702, 'max_features': 300, 'learning_method': 'batch', 'learning_decay': 0.5672049989109924, 'learning_offset': 8.445307646129525, 'max_iter': 5, 'batch_size': 113, 'max_doc_update_iter': 0}. Best is trial 12 with value: 0.5914937865440609.\n",
      "[I 2024-08-27 19:54:31,329] Trial 2 finished with value: 1.0 and parameters: {'norm': None, 'smooth_idf': True, 'sublinear_tf': False, 'stop_words': ['her', 'nevertheless', 'itself', 'so', 'or', 'will', 'still', 'take', 'indeed', 'could', 'latterly', 'whether', 'third', 'really', 'con', 'ours', 'somewhere', 'system', 'what', 'why', 'de', 'been', 'make', 'others', 'latter', 'that', 'mostly', 'don', 'becoming', 'nor', 're', 'bottom', 'off', 'beforehand', 'against', 'whereas', 'part', 'towards', 'throughout', 'might', 'too', 'sometime', 'perhaps', 'thereafter', 'and', 'often', 'very', 'moreover', 'on', 'am', 'ie', 'interest', 'with', 'other', 'nowhere', 'eight', 'rather', 'however', 'hereafter', 'should', 'no', 'say', 'the', 'forty', 'were', 'eg', 'full', 'either', 'upon', 'ten', 'afterwards', 'nine', 'your', 'since', 'around', 'for', 'well', 'just', 'these', 'using', 'while', 'therein', 'you', 'hers', 'everyone', 'several', 'herein', 'amongst', 'detail', 'get', 'thence', 'themselves', 'herself', 'are', 'one', 'here', 'became', 'via', 'seems', 'six', 'own', 'further', 'none', 'below', 'seem', 'sincere', 'anywhere', 'toward', 'mine', 'be', 'some', 'they', 'she', 'now', 'than', 'thereby', 'three', 'cry', 'wherever', 'yourselves', 'regarding', 'kg', 'whither', 'yet', 'until', 'yourself', 'before', 'into', 'out', 'find', 'everything', 'has', 'thin', 'anyhow', 'not', 'without', 'only', 'an', 'fifty', 'put', 'there', 'anyone', 'didn', 'hereby', 'wherein', 'whole', 'all', 'under', 'becomes', 'former', 'please', 'of', 'between', 'to', 'km', 'above', 'both', 'amoungst', 'how', 'in', 'this', 'whenever', 'eleven', 'side', 'must', 'much', 'almost', 'whoever', 'seeming', 'where', 'then', 'whose', 'due', 'within', 'thru', 'every', 'being', 'have', 'ourselves', 'at', 'somehow', 'thus', 'those', 'by', 'name', 'go', 'was', 'among', 'five', 'whence', 'elsewhere', 'twenty', 'across', 'anyway', 'because', 'nobody', 'therefore', 'next', 'become', 'i', 'top', 'couldnt', 'call', 'keep', 'hasnt', 'quite', 'us', 'cant', 'hence', 'ltd', 'can', 'me', 'thereupon', 'front', 'less', 'also', 'move', 'always', 'a', 'had', 'otherwise', 'serious', 'him', 'any', 'over', 'namely', 'used', 'once', 'beyond', 'such', 'them', 'least', 'never', 'down', 'four', 'nothing', 'would', 'about', 'bill', 'most', 'else', 'describe', 'up', 'from', 'fill', 'etc', 'through', 'hereupon', 'his', 'noone', 'enough', 'is', 'back', 'its', 'sixty', 'various', 'everywhere', 'but', 'two', 'inc', 'hundred', 'we', 'if', 'someone', 'give', 'thick', 'fire', 'each', 'along', 'more', 'he', 'whereafter', 'twelve', 'together', 'first', 'again', 'besides', 'yours', 'during', 'co', 'our', 'ever', 'though', 'whereupon', 'himself', 'few', 'something', 'when', 'it', 'behind', 'doing', 'who', 'seemed', 'formerly', 'except', 'alone', 'meanwhile', 'done', 'see', 'after', 'their', 'already', 'myself', 'empty', 'neither', 'does', 'per', 'whom', 'did', 'doesn', 'although', 'show', 'another', 'my', 'which', 'whereby', 'last', 'anything', 'computer', 'do', 'onto', 'mill', 'cannot', 'whatever', 'found', 'beside', 'sometimes', 'amount', 'as', 'same', 'un', 'may', 'many', 'fifteen', 'even', 'unless', 'made'], 'max_df': 0.5091786290738047, 'min_df': 0.35429412498437285, 'max_features': None, 'learning_method': 'online', 'learning_decay': 0.8610805171951537, 'learning_offset': 6.960055979675745, 'max_iter': 5, 'batch_size': 49, 'max_doc_update_iter': 0}. Best is trial 2 with value: 1.0.\n",
      "[I 2024-08-27 19:54:31,518] Trial 6 finished with value: 0.6296093662378028 and parameters: {'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': False, 'stop_words': None, 'max_df': 0.9279264389756932, 'min_df': 0.2116038403844448, 'max_features': 100, 'learning_method': 'online', 'learning_decay': 0.7788354499568577, 'learning_offset': 8.095784481943667, 'max_iter': 10, 'batch_size': 100, 'max_doc_update_iter': 0}. Best is trial 2 with value: 1.0.\n",
      "[I 2024-08-27 19:54:31,892] Trial 10 finished with value: 0.46451214016646397 and parameters: {'norm': 'l2', 'smooth_idf': True, 'sublinear_tf': True, 'stop_words': None, 'max_df': 0.6326430417808584, 'min_df': 0.07773714186326741, 'max_features': 150, 'learning_method': 'online', 'learning_decay': 0.6525087102613544, 'learning_offset': 18.241725518507504, 'max_iter': 9, 'batch_size': 60, 'max_doc_update_iter': 0}. Best is trial 2 with value: 1.0.\n",
      "[I 2024-08-27 19:54:32,309] Trial 13 finished with value: 0.46127856721094035 and parameters: {'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'stop_words': 'english', 'max_df': 0.5339318937863887, 'min_df': 0.28094257907096887, 'max_features': 150, 'learning_method': 'batch', 'learning_decay': 0.8636373503245046, 'learning_offset': 8.328042391766584, 'max_iter': 14, 'batch_size': 70, 'max_doc_update_iter': 0}. Best is trial 2 with value: 1.0.\n",
      "[I 2024-08-27 19:54:32,752] Trial 9 finished with value: 0.6729455397762495 and parameters: {'norm': 'l2', 'smooth_idf': False, 'sublinear_tf': False, 'stop_words': None, 'max_df': 0.5241014988564707, 'min_df': 0.15071194605339777, 'max_features': 100, 'learning_method': 'online', 'learning_decay': 0.6397174816939125, 'learning_offset': 10.465818689679905, 'max_iter': 11, 'batch_size': 57, 'max_doc_update_iter': 0}. Best is trial 2 with value: 1.0.\n",
      "[I 2024-08-27 19:54:34,610] Trial 4 finished with value: 0.46127856721094035 and parameters: {'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': True, 'stop_words': 'english', 'max_df': 0.7276207340968012, 'min_df': 0.30931979501776263, 'max_features': None, 'learning_method': 'online', 'learning_decay': 0.5215030182680918, 'learning_offset': 8.74505363755933, 'max_iter': 16, 'batch_size': 9, 'max_doc_update_iter': 0}. Best is trial 2 with value: 1.0.\n",
      "[I 2024-08-27 19:54:35,693] Trial 7 finished with value: 0.5823290377742875 and parameters: {'norm': 'l1', 'smooth_idf': False, 'sublinear_tf': True, 'stop_words': ['her', 'nevertheless', 'itself', 'so', 'or', 'will', 'still', 'take', 'indeed', 'could', 'latterly', 'whether', 'third', 'really', 'con', 'ours', 'somewhere', 'system', 'what', 'why', 'de', 'been', 'make', 'others', 'latter', 'that', 'mostly', 'don', 'becoming', 'nor', 're', 'bottom', 'off', 'beforehand', 'against', 'whereas', 'part', 'towards', 'throughout', 'might', 'too', 'sometime', 'perhaps', 'thereafter', 'and', 'often', 'very', 'moreover', 'on', 'am', 'ie', 'interest', 'with', 'other', 'nowhere', 'eight', 'rather', 'however', 'hereafter', 'should', 'no', 'say', 'the', 'forty', 'were', 'eg', 'full', 'either', 'upon', 'ten', 'afterwards', 'nine', 'your', 'since', 'around', 'for', 'well', 'just', 'these', 'using', 'while', 'therein', 'you', 'hers', 'everyone', 'several', 'herein', 'amongst', 'detail', 'get', 'thence', 'themselves', 'herself', 'are', 'one', 'here', 'became', 'via', 'seems', 'six', 'own', 'further', 'none', 'below', 'seem', 'sincere', 'anywhere', 'toward', 'mine', 'be', 'some', 'they', 'she', 'now', 'than', 'thereby', 'three', 'cry', 'wherever', 'yourselves', 'regarding', 'kg', 'whither', 'yet', 'until', 'yourself', 'before', 'into', 'out', 'find', 'everything', 'has', 'thin', 'anyhow', 'not', 'without', 'only', 'an', 'fifty', 'put', 'there', 'anyone', 'didn', 'hereby', 'wherein', 'whole', 'all', 'under', 'becomes', 'former', 'please', 'of', 'between', 'to', 'km', 'above', 'both', 'amoungst', 'how', 'in', 'this', 'whenever', 'eleven', 'side', 'must', 'much', 'almost', 'whoever', 'seeming', 'where', 'then', 'whose', 'due', 'within', 'thru', 'every', 'being', 'have', 'ourselves', 'at', 'somehow', 'thus', 'those', 'by', 'name', 'go', 'was', 'among', 'five', 'whence', 'elsewhere', 'twenty', 'across', 'anyway', 'because', 'nobody', 'therefore', 'next', 'become', 'i', 'top', 'couldnt', 'call', 'keep', 'hasnt', 'quite', 'us', 'cant', 'hence', 'ltd', 'can', 'me', 'thereupon', 'front', 'less', 'also', 'move', 'always', 'a', 'had', 'otherwise', 'serious', 'him', 'any', 'over', 'namely', 'used', 'once', 'beyond', 'such', 'them', 'least', 'never', 'down', 'four', 'nothing', 'would', 'about', 'bill', 'most', 'else', 'describe', 'up', 'from', 'fill', 'etc', 'through', 'hereupon', 'his', 'noone', 'enough', 'is', 'back', 'its', 'sixty', 'various', 'everywhere', 'but', 'two', 'inc', 'hundred', 'we', 'if', 'someone', 'give', 'thick', 'fire', 'each', 'along', 'more', 'he', 'whereafter', 'twelve', 'together', 'first', 'again', 'besides', 'yours', 'during', 'co', 'our', 'ever', 'though', 'whereupon', 'himself', 'few', 'something', 'when', 'it', 'behind', 'doing', 'who', 'seemed', 'formerly', 'except', 'alone', 'meanwhile', 'done', 'see', 'after', 'their', 'already', 'myself', 'empty', 'neither', 'does', 'per', 'whom', 'did', 'doesn', 'although', 'show', 'another', 'my', 'which', 'whereby', 'last', 'anything', 'computer', 'do', 'onto', 'mill', 'cannot', 'whatever', 'found', 'beside', 'sometimes', 'amount', 'as', 'same', 'un', 'may', 'many', 'fifteen', 'even', 'unless', 'made'], 'max_df': 0.5115751252241086, 'min_df': 0.053332109841964015, 'max_features': None, 'learning_method': 'online', 'learning_decay': 0.5883530664139064, 'learning_offset': 16.107606356238875, 'max_iter': 16, 'batch_size': 8, 'max_doc_update_iter': 0}. Best is trial 2 with value: 1.0.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial,fulldatadf\u001b[38;5;241m.\u001b[39mdescription),n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:99\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[1;32m---> 99\u001b[0m                         f\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    101\u001b[0m                 futures\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    102\u001b[0m                     executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    103\u001b[0m                         _optimize_sequential,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m                     )\n\u001b[0;32m    115\u001b[0m                 )\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial,fulldatadf\u001b[38;5;241m.\u001b[39mdescription),n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[9], line 34\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial:Trial,x:pd\u001b[38;5;241m.\u001b[39mDataFrame)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m     32\u001b[0m     model\u001b[38;5;241m=\u001b[39minst_pipeTFLDA(trial)\n\u001b[1;32m---> 34\u001b[0m     pipe\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(x)\n\u001b[0;32m     35\u001b[0m     score\u001b[38;5;241m=\u001b[39mtopiccoherencescorer(pipe,x)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:471\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 471\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, routed_params)\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:408\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    406\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    409\u001b[0m     cloned_transformer,\n\u001b[0;32m    410\u001b[0m     X,\n\u001b[0;32m    411\u001b[0m     y,\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    413\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    414\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    415\u001b[0m     params\u001b[38;5;241m=\u001b[39mrouted_params[name],\n\u001b[0;32m    416\u001b[0m )\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:1303\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1303\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1305\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1306\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1307\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2138\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2133\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2134\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2135\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2136\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2137\u001b[0m )\n\u001b[1;32m-> 2138\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2140\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lekle\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1399\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1397\u001b[0m min_doc_count \u001b[38;5;241m=\u001b[39m min_df \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(min_df, Integral) \u001b[38;5;28;01melse\u001b[39;00m min_df \u001b[38;5;241m*\u001b[39m n_doc\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_doc_count \u001b[38;5;241m<\u001b[39m min_doc_count:\n\u001b[1;32m-> 1399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_df corresponds to < documents than min_df\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1401\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_features(X, vocabulary)\n",
      "\u001b[1;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": [
    "study.optimize(lambda trial: objective(trial,fulldatadf.description),n_trials=100,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study,cwd.joinpath(f'study_{study.study_name}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
