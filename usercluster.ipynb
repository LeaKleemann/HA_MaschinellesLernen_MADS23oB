{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting started, importing the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib2 as pathlib\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the right path to load the data\n",
    "\n",
    "cwd=pathlib.Path.cwd()\n",
    "datadirpath=cwd.joinpath(\"data\")\n",
    "rawdatapath=datadirpath.joinpath(\"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'book_id', 'user_id_mapping', 'book_id_mapping',\n",
      "       'Predicted Rating', 'Actual Rating'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load the data about the reviews of individual users, deleting the first index column, printing the left columns\n",
    "reviewdf=pd.read_csv(rawdatapath.joinpath(\"collaborative_books_df.csv\"))\n",
    "reviewdf=reviewdf.drop([reviewdf.columns[0]],axis=1) # removed unnamed index column\n",
    "print(reviewdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196296, 6)\n"
     ]
    }
   ],
   "source": [
    "#looking at the dimensions of the dataset\n",
    "\n",
    "print (reviewdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['book_id', 'title', 'image_url', 'url', 'num_pages', 'ratings_count',\n",
      "       'description', 'genre', 'name', 'book_id_mapping'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#loading the metadata of the 96 books that we have\n",
    "\n",
    "metadatadf=pd.read_csv(rawdatapath.joinpath(\"collaborative_book_metadata.csv\"))\n",
    "metadatadf=metadatadf.drop([metadatadf.columns[0]],axis=1) # removed unnamed index column\n",
    "print(metadatadf.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17248, 15)\n",
      "              title_x  book_id  user_id_mapping  book_id_mapping_x  \\\n",
      "0  I Am the Messenger    19057             1537                299   \n",
      "1  I Am the Messenger    19057            23039                299   \n",
      "2  I Am the Messenger    19057            39096                299   \n",
      "3  I Am the Messenger    19057            14631                299   \n",
      "4  I Am the Messenger    19057            32816                299   \n",
      "\n",
      "   Predicted Rating  Actual Rating             title_y  \\\n",
      "0               4.5              5  I Am the Messenger   \n",
      "1               4.9              3  I Am the Messenger   \n",
      "2               3.9              3  I Am the Messenger   \n",
      "3               4.7              4  I Am the Messenger   \n",
      "4               4.3              5  I Am the Messenger   \n",
      "\n",
      "                                           image_url  \\\n",
      "0  https://images.gr-assets.com/books/1398483261m...   \n",
      "1  https://images.gr-assets.com/books/1398483261m...   \n",
      "2  https://images.gr-assets.com/books/1398483261m...   \n",
      "3  https://images.gr-assets.com/books/1398483261m...   \n",
      "4  https://images.gr-assets.com/books/1398483261m...   \n",
      "\n",
      "                                                 url  num_pages  \\\n",
      "0  https://www.goodreads.com/book/show/19057.I_Am...        360   \n",
      "1  https://www.goodreads.com/book/show/19057.I_Am...        360   \n",
      "2  https://www.goodreads.com/book/show/19057.I_Am...        360   \n",
      "3  https://www.goodreads.com/book/show/19057.I_Am...        360   \n",
      "4  https://www.goodreads.com/book/show/19057.I_Am...        360   \n",
      "\n",
      "   ratings_count                                        description  \\\n",
      "0          94968  protect the diamonds\\nsurvive the clubs\\ndig d...   \n",
      "1          94968  protect the diamonds\\nsurvive the clubs\\ndig d...   \n",
      "2          94968  protect the diamonds\\nsurvive the clubs\\ndig d...   \n",
      "3          94968  protect the diamonds\\nsurvive the clubs\\ndig d...   \n",
      "4          94968  protect the diamonds\\nsurvive the clubs\\ndig d...   \n",
      "\n",
      "                                               genre          name  \\\n",
      "0  ['young-adult', 'fiction', 'mystery, thriller,...  Markus Zusak   \n",
      "1  ['young-adult', 'fiction', 'mystery, thriller,...  Markus Zusak   \n",
      "2  ['young-adult', 'fiction', 'mystery, thriller,...  Markus Zusak   \n",
      "3  ['young-adult', 'fiction', 'mystery, thriller,...  Markus Zusak   \n",
      "4  ['young-adult', 'fiction', 'mystery, thriller,...  Markus Zusak   \n",
      "\n",
      "   book_id_mapping_y  \n",
      "0                455  \n",
      "1                455  \n",
      "2                455  \n",
      "3                455  \n",
      "4                455  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge the 2 datasets  on 'book_id' to get enriched data of reviewd books\n",
    "merged_df = pd.merge(reviewdf, metadatadf, on='book_id')\n",
    "\n",
    "#  Save the merged DataFrame to a new CSV file (just in case)\n",
    "merged_df.to_csv('merged_books.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the merged DataFrame\n",
    "print(merged_df.shape) # only 17.248 of 196296 lines are left, so we have 17.248 reviews for the 96 books\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 rows with an empty \"num_pages\" column.\n",
      "(17248, 15)\n",
      "Index(['title_x', 'book_id', 'user_id_mapping', 'book_id_mapping_x',\n",
      "       'Predicted Rating', 'Actual Rating', 'title_y', 'image_url', 'url',\n",
      "       'num_pages', 'ratings_count', 'description', 'genre', 'name',\n",
      "       'book_id_mapping_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ensure, we have no rows, that do not have the additional metadata Find rows with empty (NaN) values in the 'num_pages' column\n",
    "empty_num_pages_count = merged_df['image_url'].isna().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f'There are {empty_num_pages_count} rows with an empty \"num_pages\" column.')\n",
    "print (merged_df.shape)\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 rows with different values in \"title_x\" and \"title_y\".\n",
      "Empty DataFrame\n",
      "Columns: [title_x, title_y]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Compare the columns 'title_x' and 'title_y' and find out if there is any row where there are differences\n",
    "differences = merged_df['title_x'] != merged_df['title_y']\n",
    "\n",
    "# Find out how many rows have different values\n",
    "num_differences = differences.sum()\n",
    "print(f'There are {num_differences} rows with different values in \"title_x\" and \"title_y\".')\n",
    "\n",
    "# Display the rows with differences\n",
    "diff_rows = merged_df[differences]\n",
    "print(diff_rows[['title_x', 'title_y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title_x', 'book_id', 'user_id_mapping', 'book_id_mapping_x',\n",
      "       'Predicted Rating', 'Actual Rating', 'image_url', 'url', 'num_pages',\n",
      "       'ratings_count', 'description', 'genre', 'name', 'book_id_mapping_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deleting the 'title_y' column as it is similar to 'title_x', see verification above\n",
    "merged_df = merged_df.drop(merged_df.columns[6],axis=1)\n",
    "#reviewdf=reviewdf.drop([reviewdf.columns[0]],axis=1) # removed unnamed index column\n",
    "\n",
    "\n",
    "# To confirm the column is deleted, print the  columns again\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data about users and their ratings, so that each user is represented by one row, that includes their rating history\n",
    "#  create a user-item matrix\n",
    "user_item_matrix = merged_df.pivot(index='user_id_mapping', \n",
    "                                   columns='book_id_mapping_x', \n",
    "                                   values='Actual Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle mising values - as a next step find out how to import the average rating from \"book_titles.csv\"\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "user_item_matrix_imputed = pd.DataFrame(imputer.fit_transform(user_item_matrix),\n",
    "                                        columns=user_item_matrix.columns,\n",
    "                                        index=user_item_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erst mal nicht machen, hat nicht geholfen\n",
    "# Convert all genre names to lowercase and strip whitespace\n",
    "#merged_df['genre_split'] = merged_df['genre_split'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, split the 'genre' column into multiple rows\n",
    "# Explode splits lists of genres into separate rows per genre\n",
    "# \n",
    "merged_df['genre_split'] = merged_df['genre'].str.split(', ')\n",
    "merged_df = merged_df.explode('genre_split')\n",
    "\n",
    "# Now apply one-hot encoding to the 'genre_split' column\n",
    "genre_one_hot = pd.get_dummies(merged_df['genre_split'], prefix='Genre')\n",
    "\n",
    "# Group by 'user_id_mapping' and 'book_id_mapping_x' and sum the one-hot encoded genres\n",
    "merged_df = merged_df.drop(columns=['genre'])  # Drop original genre if no longer needed\n",
    "merged_df = pd.concat([merged_df, genre_one_hot], axis=1)\n",
    "\n",
    "# You may need to re-aggregate if you had exploded the DataFrame:\n",
    "merged_df = merged_df.groupby(['user_id_mapping', 'book_id_mapping_x'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erst mal nicht, hat nicht geholfen \n",
    "# once more one-hot enconding with cleaned up genre columns\n",
    "# Perform one-hot encoding again on the standardized genres\n",
    "#genre_one_hot = pd.get_dummies(merged_df['genre_split'], prefix='Genre')\n",
    "\n",
    "# Concatenate the one-hot encoded genres with the original DataFrame\n",
    "#merged_df = pd.concat([merged_df, genre_one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id_mapping', 'book_id_mapping_x', 'title_x', 'book_id',\n",
      "       'Predicted Rating', 'Actual Rating', 'image_url', 'url', 'num_pages',\n",
      "       'ratings_count', 'description', 'name', 'book_id_mapping_y',\n",
      "       'genre_split', 'Genre_'children'', 'Genre_'children']', 'Genre_'comics',\n",
      "       'Genre_'fantasy', 'Genre_'fiction'', 'Genre_'fiction']',\n",
      "       'Genre_'history', 'Genre_'mystery', 'Genre_'non-fiction'',\n",
      "       'Genre_'non-fiction']', 'Genre_'poetry'', 'Genre_'poetry']',\n",
      "       'Genre_'romance'', 'Genre_'romance']', 'Genre_'young-adult'',\n",
      "       'Genre_'young-adult']', 'Genre_['children'', 'Genre_['comics',\n",
      "       'Genre_['fantasy', 'Genre_['fiction'', 'Genre_['mystery',\n",
      "       'Genre_['non-fiction'', 'Genre_['non-fiction']', 'Genre_['poetry'',\n",
      "       'Genre_['romance'', 'Genre_['young-adult'', 'Genre_biography'',\n",
      "       'Genre_biography']', 'Genre_crime'', 'Genre_crime']', 'Genre_graphic'',\n",
      "       'Genre_graphic']', 'Genre_historical fiction', 'Genre_paranormal'',\n",
      "       'Genre_paranormal']', 'Genre_thriller'],\n",
      "      dtype='object')\n",
      "<bound method NDFrame.head of        user_id_mapping  book_id_mapping_x  \\\n",
      "0                    0                413   \n",
      "1                    0                753   \n",
      "2                    0                847   \n",
      "3                    1                268   \n",
      "4                    3                846   \n",
      "...                ...                ...   \n",
      "17243            83971                450   \n",
      "17244            84075                230   \n",
      "17245            84107                313   \n",
      "17246            84228                846   \n",
      "17247            84290                562   \n",
      "\n",
      "                                                 title_x   book_id  \\\n",
      "0      Pride and Prejudice and Zombies Pride and Prej...  64897569   \n",
      "1      Persepolis The Story of a Childhood Persepolis...     76128   \n",
      "2      A Child Called It Dave Pelzer 1A Child Called ...    728976   \n",
      "3      Sharp ObjectsSharp ObjectsSharp ObjectsSharp O...    266236   \n",
      "4      The Coincidence of Callie Kayden The Coinciden...  48341373   \n",
      "...                                                  ...       ...   \n",
      "17243                       Eleven MinutesEleven Minutes      2860   \n",
      "17244  The Ultimate Hitchhikers Guide to the GalaxyTh...        52   \n",
      "17245  Me Before You Me Before You 1Me Before You Me ...  31015916   \n",
      "17246  The Coincidence of Callie Kayden The Coinciden...  48341373   \n",
      "17247  Fallen Too Far Rosemary Beach 1 Too Far 1Falle...  48212709   \n",
      "\n",
      "       Predicted Rating  Actual Rating  \\\n",
      "0                  33.0             44   \n",
      "1                  37.6             40   \n",
      "2                  33.6             36   \n",
      "3                  12.8             16   \n",
      "4                  11.4             12   \n",
      "...                 ...            ...   \n",
      "17243               5.4              8   \n",
      "17244              16.8             20   \n",
      "17245               3.4              8   \n",
      "17246              11.4             15   \n",
      "17247              15.0             15   \n",
      "\n",
      "                                               image_url  \\\n",
      "0      https://images.gr-assets.com/books/1320449653m...   \n",
      "1      https://images.gr-assets.com/books/1425871473m...   \n",
      "2      https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "3      https://images.gr-assets.com/books/1423241485m...   \n",
      "4      https://images.gr-assets.com/books/1353550763m...   \n",
      "...                                                  ...   \n",
      "17243  https://images.gr-assets.com/books/1358266987m...   \n",
      "17244  https://images.gr-assets.com/books/1404613595m...   \n",
      "17245  https://images.gr-assets.com/books/1357108762m...   \n",
      "17246  https://images.gr-assets.com/books/1353550763m...   \n",
      "17247  https://images.gr-assets.com/books/1349565157m...   \n",
      "\n",
      "                                                     url  num_pages  \\\n",
      "0      https://www.goodreads.com/book/show/5899779-pr...       3520   \n",
      "1      https://www.goodreads.com/book/show/9516.Perse...       1224   \n",
      "2      https://www.goodreads.com/book/show/60748.A_Ch...       2208   \n",
      "3      https://www.goodreads.com/book/show/66559.Shar...       1016   \n",
      "4      https://www.goodreads.com/book/show/16113791-t...        849   \n",
      "...                                                  ...        ...   \n",
      "17243  https://www.goodreads.com/book/show/1430.Eleve...        546   \n",
      "17244  https://www.goodreads.com/book/show/13.The_Ult...       3260   \n",
      "17245  https://www.goodreads.com/book/show/15507958-m...        738   \n",
      "17246  https://www.goodreads.com/book/show/16113791-t...        849   \n",
      "17247  https://www.goodreads.com/book/show/16070903-f...        900   \n",
      "\n",
      "       ratings_count  ... Genre_biography' Genre_biography']  Genre_crime'  \\\n",
      "0            1160907  ...                1                 0             0   \n",
      "1             955760  ...                1                 0             0   \n",
      "2            3771432  ...                1                 0             0   \n",
      "3             833576  ...                0                 0             1   \n",
      "4             295314  ...                0                 0             0   \n",
      "...              ...  ...              ...               ...           ...   \n",
      "17243         208480  ...                0                 0             0   \n",
      "17244         902504  ...                0                 0             0   \n",
      "17245        1218654  ...                0                 0             0   \n",
      "17246         295314  ...                0                 0             0   \n",
      "17247         421260  ...                0                 0             0   \n",
      "\n",
      "      Genre_crime']  Genre_graphic'  Genre_graphic']  \\\n",
      "0                 1               0                0   \n",
      "1                 0               1                0   \n",
      "2                 1               1                0   \n",
      "3                 0               0                0   \n",
      "4                 0               0                0   \n",
      "...             ...             ...              ...   \n",
      "17243             0               0                0   \n",
      "17244             0               0                0   \n",
      "17245             0               0                0   \n",
      "17246             0               0                0   \n",
      "17247             0               0                0   \n",
      "\n",
      "       Genre_historical fiction  Genre_paranormal'  Genre_paranormal']  \\\n",
      "0                             1                  1                   0   \n",
      "1                             1                  0                   0   \n",
      "2                             1                  0                   0   \n",
      "3                             0                  0                   0   \n",
      "4                             0                  0                   0   \n",
      "...                         ...                ...                 ...   \n",
      "17243                         0                  0                   0   \n",
      "17244                         0                  1                   0   \n",
      "17245                         0                  0                   0   \n",
      "17246                         0                  0                   0   \n",
      "17247                         0                  0                   0   \n",
      "\n",
      "       Genre_thriller  \n",
      "0                   1  \n",
      "1                   0  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   0  \n",
      "...               ...  \n",
      "17243               0  \n",
      "17244               0  \n",
      "17245               0  \n",
      "17246               0  \n",
      "17247               0  \n",
      "\n",
      "[17248 rows x 50 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)\n",
    "print(merged_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id_mapping', 'book_id_mapping_x', 'title_x', 'book_id',\n",
      "       'Predicted Rating', 'Actual Rating', 'image_url', 'url', 'num_pages',\n",
      "       'ratings_count', 'description', 'name', 'book_id_mapping_y',\n",
      "       'genre_split', 'genre_children', 'genre_children', 'genre_comics',\n",
      "       'genre_fantasy', 'genre_fiction', 'genre_fiction', 'genre_history',\n",
      "       'genre_mystery', 'genre_non-fiction', 'genre_non-fiction',\n",
      "       'genre_poetry', 'genre_poetry', 'genre_romance', 'genre_romance',\n",
      "       'genre_young-adult', 'genre_young-adult', 'genre_children',\n",
      "       'genre_comics', 'genre_fantasy', 'genre_fiction', 'genre_mystery',\n",
      "       'genre_non-fiction', 'genre_non-fiction', 'genre_poetry',\n",
      "       'genre_romance', 'genre_young-adult', 'genre_biography',\n",
      "       'genre_biography', 'genre_crime', 'genre_crime', 'genre_graphic',\n",
      "       'genre_graphic', 'genre_historical fiction', 'genre_paranormal',\n",
      "       'genre_paranormal', 'genre_thriller'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean up genre names\n",
    "def clean_genre_name(genre_name):\n",
    "    # Remove leading/trailing quotes and brackets\n",
    "    cleaned_name = re.sub(r\"[\\[\\]']+\", \"\", genre_name)\n",
    "    # Convert to lowercase and strip leading/trailing whitespace\n",
    "    cleaned_name = cleaned_name.strip().lower()\n",
    "    return cleaned_name\n",
    "\n",
    "# Clean up the column names in the DataFrame\n",
    "cleaned_columns = {col: clean_genre_name(col) for col in merged_df.columns if col.startswith('Genre_')}\n",
    "merged_df.rename(columns=cleaned_columns, inplace=True)\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id_mapping', 'book_id_mapping_x', 'title_x', 'book_id',\n",
      "       'Predicted Rating', 'Actual Rating', 'image_url', 'url', 'num_pages',\n",
      "       'ratings_count', 'description', 'name', 'book_id_mapping_y',\n",
      "       'genre_split', 'genre_children', 'genre_comics', 'genre_fantasy',\n",
      "       'genre_fiction', 'genre_history', 'genre_mystery', 'genre_non-fiction',\n",
      "       'genre_poetry', 'genre_romance', 'genre_young-adult', 'genre_biography',\n",
      "       'genre_crime', 'genre_graphic', 'genre_historical fiction',\n",
      "       'genre_paranormal', 'genre_thriller'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping for similar genres to merge them\n",
    "# This step assumes that after cleaning, some genres will have identical names and should be merged\n",
    "unique_genres = list(set(cleaned_columns.values()))  # Get unique cleaned genre names\n",
    "\n",
    "# Initialize columns for cleaned genres if not already existing\n",
    "for genre in unique_genres:\n",
    "    if genre not in merged_df.columns:\n",
    "        merged_df[genre] = 0\n",
    "\n",
    "# Sum the columns that are considered similar\n",
    "for original_col in cleaned_columns.values():\n",
    "    merged_df[original_col] = merged_df.filter(like=original_col).sum(axis=1)\n",
    "\n",
    "# Remove duplicate columns\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "\n",
    "# Optionally, remove any genres with no entries after merging\n",
    "merged_df = merged_df.loc[:, (merged_df != 0).any(axis=0)]\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id_mapping  book_id_mapping_x  \\\n",
      "0                0                413   \n",
      "1                0                753   \n",
      "2                0                847   \n",
      "3                1                268   \n",
      "4                3                846   \n",
      "\n",
      "                                             title_x   book_id  \\\n",
      "0  Pride and Prejudice and Zombies Pride and Prej...  64897569   \n",
      "1  Persepolis The Story of a Childhood Persepolis...     76128   \n",
      "2  A Child Called It Dave Pelzer 1A Child Called ...    728976   \n",
      "3  Sharp ObjectsSharp ObjectsSharp ObjectsSharp O...    266236   \n",
      "4  The Coincidence of Callie Kayden The Coinciden...  48341373   \n",
      "\n",
      "   Predicted Rating  Actual Rating  \\\n",
      "0              33.0             44   \n",
      "1              37.6             40   \n",
      "2              33.6             36   \n",
      "3              12.8             16   \n",
      "4              11.4             12   \n",
      "\n",
      "                                           image_url  \\\n",
      "0  https://images.gr-assets.com/books/1320449653m...   \n",
      "1  https://images.gr-assets.com/books/1425871473m...   \n",
      "2  https://s.gr-assets.com/assets/nophoto/book/11...   \n",
      "3  https://images.gr-assets.com/books/1423241485m...   \n",
      "4  https://images.gr-assets.com/books/1353550763m...   \n",
      "\n",
      "                                                 url  num_pages  \\\n",
      "0  https://www.goodreads.com/book/show/5899779-pr...       3520   \n",
      "1  https://www.goodreads.com/book/show/9516.Perse...       1224   \n",
      "2  https://www.goodreads.com/book/show/60748.A_Ch...       2208   \n",
      "3  https://www.goodreads.com/book/show/66559.Shar...       1016   \n",
      "4  https://www.goodreads.com/book/show/16113791-t...        849   \n",
      "\n",
      "   ratings_count  ... genre_non-fiction genre_poetry  genre_romance  \\\n",
      "0        1160907  ...                 0            0              9   \n",
      "1         955760  ...                64            0              0   \n",
      "2        3771432  ...                64            0              0   \n",
      "3         833576  ...                 0            0              0   \n",
      "4         295314  ...                 0            0              9   \n",
      "\n",
      "  genre_young-adult  genre_biography  genre_crime  genre_graphic  \\\n",
      "0                 9                2            2              0   \n",
      "1                 9                2            0              2   \n",
      "2                 9                2            2              2   \n",
      "3                 0                0            2              0   \n",
      "4                 9                0            0              0   \n",
      "\n",
      "   genre_historical fiction  genre_paranormal  genre_thriller  \n",
      "0                         1                 2               1  \n",
      "1                         1                 0               0  \n",
      "2                         1                 0               1  \n",
      "3                         0                 0               1  \n",
      "4                         0                 0               0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "Index(['user_id_mapping', 'book_id_mapping_x', 'title_x', 'book_id',\n",
      "       'Predicted Rating', 'Actual Rating', 'image_url', 'url', 'num_pages',\n",
      "       'ratings_count', 'description', 'name', 'book_id_mapping_y',\n",
      "       'genre_split', 'genre_children', 'genre_comics', 'genre_fantasy',\n",
      "       'genre_fiction', 'genre_history', 'genre_mystery', 'genre_non-fiction',\n",
      "       'genre_poetry', 'genre_romance', 'genre_young-adult', 'genre_biography',\n",
      "       'genre_crime', 'genre_graphic', 'genre_historical fiction',\n",
      "       'genre_paranormal', 'genre_thriller'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   book_id_mapping_x  num_pages  ratings_count  \\\n",
      "0                413       3520        1160907   \n",
      "1                753       1224         955760   \n",
      "2                847       2208        3771432   \n",
      "3                268       1016         833576   \n",
      "4                846        849         295314   \n",
      "\n",
      "                                         genre_split  genre_children  \\\n",
      "0  ['fantasyparanormal''romance''fiction''history...               0   \n",
      "1  ['comicsgraphic''non-fiction''historyhistorica...               0   \n",
      "2  ['non-fiction''historyhistorical fictionbiogra...               9   \n",
      "3                  ['mysterythrillercrime''fiction']               0   \n",
      "4                  ['romance''young-adult''fiction']               0   \n",
      "\n",
      "   genre_comics  genre_fantasy  genre_fiction  genre_history  genre_mystery  \\\n",
      "0             0              2              9              1              2   \n",
      "1             2              0              9              1              0   \n",
      "2             2              0              9              1              2   \n",
      "3             0              0              9              0              2   \n",
      "4             0              0              9              0              0   \n",
      "\n",
      "   genre_non-fiction  genre_poetry  genre_romance  genre_young-adult  \\\n",
      "0                  0             0              9                  9   \n",
      "1                 64             0              0                  9   \n",
      "2                 64             0              0                  9   \n",
      "3                  0             0              0                  0   \n",
      "4                  0             0              9                  9   \n",
      "\n",
      "   genre_biography  genre_crime  genre_graphic  genre_historical fiction  \\\n",
      "0                2            2              0                         1   \n",
      "1                2            0              2                         1   \n",
      "2                2            2              2                         1   \n",
      "3                0            2              0                         0   \n",
      "4                0            0              0                         0   \n",
      "\n",
      "   genre_paranormal  genre_thriller  \n",
      "0                 2               1  \n",
      "1                 0               0  \n",
      "2                 0               1  \n",
      "3                 0               1  \n",
      "4                 0               0  \n",
      "Index(['book_id_mapping_x', 'num_pages', 'ratings_count', 'genre_split',\n",
      "       'genre_children', 'genre_comics', 'genre_fantasy', 'genre_fiction',\n",
      "       'genre_history', 'genre_mystery', 'genre_non-fiction', 'genre_poetry',\n",
      "       'genre_romance', 'genre_young-adult', 'genre_biography', 'genre_crime',\n",
      "       'genre_graphic', 'genre_historical fiction', 'genre_paranormal',\n",
      "       'genre_thriller'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant columns from merged_df\n",
    "book_metadata = merged_df[['book_id_mapping_x', 'num_pages', 'ratings_count'] + genre_columns].drop_duplicates()\n",
    "\n",
    "# Check the head of book_metadata to ensure it looks correct\n",
    "print(book_metadata.head())\n",
    "print(book_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_mapping       0         1         3         4         7         9      \\\n",
      "book_id_mapping_x                                                               \n",
      "3                  3.745690  3.745690  3.745690  3.745690  3.745690  3.745690   \n",
      "38                 4.006250  4.006250  4.006250  4.006250  4.006250  4.006250   \n",
      "79                 4.210938  4.210938  4.210938  4.210938  4.210938  4.210938   \n",
      "93                 4.245935  4.245935  4.245935  4.245935  4.245935  4.245935   \n",
      "99                 3.310160  3.310160  3.310160  3.310160  3.310160  3.310160   \n",
      "\n",
      "user_id_mapping       11        12        21        33     ...     83482  \\\n",
      "book_id_mapping_x                                          ...             \n",
      "3                  3.745690  3.745690  3.745690  3.745690  ...  3.745690   \n",
      "38                 4.006250  4.006250  4.006250  4.006250  ...  4.006250   \n",
      "79                 4.210938  4.210938  4.210938  4.210938  ...  4.210938   \n",
      "93                 4.245935  4.245935  4.245935  4.245935  ...  4.245935   \n",
      "99                 3.310160  3.310160  3.310160  3.310160  ...  3.310160   \n",
      "\n",
      "user_id_mapping       83532     83533     83695     83815     83971     84075  \\\n",
      "book_id_mapping_x                                                               \n",
      "3                  3.745690  5.000000  3.745690  3.745690  3.745690  3.745690   \n",
      "38                 4.006250  4.006250  4.006250  4.006250  4.006250  4.006250   \n",
      "79                 4.210938  4.210938  4.210938  4.210938  4.210938  4.210938   \n",
      "93                 4.245935  4.245935  3.000000  4.245935  4.245935  4.245935   \n",
      "99                 3.310160  3.310160  3.310160  3.310160  3.310160  3.310160   \n",
      "\n",
      "user_id_mapping       84107     84228     84290  \n",
      "book_id_mapping_x                                \n",
      "3                  3.745690  3.745690  3.745690  \n",
      "38                 4.006250  4.006250  4.006250  \n",
      "79                 4.210938  4.210938  4.210938  \n",
      "93                 4.245935  4.245935  4.245935  \n",
      "99                 3.310160  3.310160  3.310160  \n",
      "\n",
      "[5 rows x 15039 columns]\n",
      "Index([    0,     1,     3,     4,     7,     9,    11,    12,    21,    33,\n",
      "       ...\n",
      "       83482, 83532, 83533, 83695, 83815, 83971, 84075, 84107, 84228, 84290],\n",
      "      dtype='int64', name='user_id_mapping', length=15039)\n"
     ]
    }
   ],
   "source": [
    "print(user_item_matrix_imputed.head())\n",
    "print(user_item_matrix_imputed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_mapping     0         1         3         4         7         9      \\\n",
      "3                 3.74569   3.74569   3.74569   3.74569   3.74569   3.74569   \n",
      "38                4.00625   4.00625   4.00625   4.00625   4.00625   4.00625   \n",
      "79               4.210938  4.210938  4.210938  4.210938  4.210938  4.210938   \n",
      "93               4.245935  4.245935  4.245935  4.245935  4.245935  4.245935   \n",
      "99                3.31016   3.31016   3.31016   3.31016   3.31016   3.31016   \n",
      "\n",
      "user_id_mapping     11        12        21        33     ...     83482  \\\n",
      "3                 3.74569   3.74569   3.74569   3.74569  ...   3.74569   \n",
      "38                4.00625   4.00625   4.00625   4.00625  ...   4.00625   \n",
      "79               4.210938  4.210938  4.210938  4.210938  ...  4.210938   \n",
      "93               4.245935  4.245935  4.245935  4.245935  ...  4.245935   \n",
      "99                3.31016   3.31016   3.31016   3.31016  ...   3.31016   \n",
      "\n",
      "user_id_mapping     83532     83533     83695     83815     83971     84075  \\\n",
      "3                 3.74569       5.0   3.74569   3.74569   3.74569   3.74569   \n",
      "38                4.00625   4.00625   4.00625   4.00625   4.00625   4.00625   \n",
      "79               4.210938  4.210938  4.210938  4.210938  4.210938  4.210938   \n",
      "93               4.245935  4.245935       3.0  4.245935  4.245935  4.245935   \n",
      "99                3.31016   3.31016   3.31016   3.31016   3.31016   3.31016   \n",
      "\n",
      "user_id_mapping     84107     84228     84290  \n",
      "3                 3.74569   3.74569   3.74569  \n",
      "38                4.00625   4.00625   4.00625  \n",
      "79               4.210938  4.210938  4.210938  \n",
      "93               4.245935  4.245935  4.245935  \n",
      "99                3.31016   3.31016   3.31016  \n",
      "\n",
      "[5 rows x 15039 columns]\n",
      "Index([    0,     1,     3,     4,     7,     9,    11,    12,    21,    33,\n",
      "       ...\n",
      "       83482, 83532, 83533, 83695, 83815, 83971, 84075, 84107, 84228, 84290],\n",
      "      dtype='int64', name='user_id_mapping', length=15039)\n"
     ]
    }
   ],
   "source": [
    "# Set 'book_id_mapping_x' as index for merging\n",
    "book_metadata = book_metadata.set_index('book_id_mapping_x')\n",
    "\n",
    "# Transpose the user-item matrix to align book IDs as index\n",
    "user_item_matrix_imputed = user_item_matrix_imputed.T\n",
    "\n",
    "# Merge metadata into the user-item matrix\n",
    "user_item_with_metadata = user_item_matrix_imputed.join(book_metadata, how='left')\n",
    "\n",
    "# Transpose back to the original format\n",
    "user_item_with_metadata = user_item_with_metadata.T\n",
    "\n",
    "# Verify columns after merging\n",
    "print(user_item_with_metadata.head())\n",
    "print(user_item_with_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['book_id_mapping_x', 'num_pages', 'ratings_count', 'genre_split',\n",
      "       'genre_children', 'genre_comics', 'genre_fantasy', 'genre_fiction',\n",
      "       'genre_history', 'genre_mystery', 'genre_non-fiction', 'genre_poetry',\n",
      "       'genre_romance', 'genre_young-adult', 'genre_biography', 'genre_crime',\n",
      "       'genre_graphic', 'genre_historical fiction', 'genre_paranormal',\n",
      "       'genre_thriller'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#should not be needed anymore\n",
    "#  Remove 'genre' reference from book_metadata creation\n",
    "#book_metadata = merged_df[['book_id_mapping_x', 'num_pages', 'ratings_count']].drop_duplicates()\n",
    "\n",
    "# Add the one-hot encoded genre columns to book_metadata\n",
    "#genre_columns = [col for col in merged_df.columns if col.startswith('genre_')]\n",
    "#book_metadata = pd.concat([book_metadata, merged_df[genre_columns]], axis=1).drop_duplicates()\n",
    "#print(book_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id_mapping', 'book_id_mapping_x', 'title_x', 'book_id',\n",
      "       'Predicted Rating', 'Actual Rating', 'image_url', 'url', 'num_pages',\n",
      "       'ratings_count', 'description', 'name', 'book_id_mapping_y',\n",
      "       'genre_split', 'genre_children', 'genre_comics', 'genre_fantasy',\n",
      "       'genre_fiction', 'genre_history', 'genre_mystery', 'genre_non-fiction',\n",
      "       'genre_poetry', 'genre_romance', 'genre_young-adult', 'genre_biography',\n",
      "       'genre_crime', 'genre_graphic', 'genre_historical fiction',\n",
      "       'genre_paranormal', 'genre_thriller'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      book_id_mapping_x  num_pages  ratings_count  \\\n",
      "0                413.0     3520.0      1160907.0   \n",
      "1                753.0     1224.0       955760.0   \n",
      "2                847.0     2208.0      3771432.0   \n",
      "3                268.0     1016.0       833576.0   \n",
      "4                846.0      849.0       295314.0   \n",
      "..                 ...        ...            ...   \n",
      "403                NaN        NaN            NaN   \n",
      "475                NaN        NaN            NaN   \n",
      "531                NaN        NaN            NaN   \n",
      "678                NaN        NaN            NaN   \n",
      "804                NaN        NaN            NaN   \n",
      "\n",
      "                                           genre_split  genre_children  \\\n",
      "0    ['fantasyparanormal''romance''fiction''history...               0   \n",
      "1    ['comicsgraphic''non-fiction''historyhistorica...               0   \n",
      "2    ['non-fiction''historyhistorical fictionbiogra...               9   \n",
      "3                    ['mysterythrillercrime''fiction']               0   \n",
      "4                    ['romance''young-adult''fiction']               0   \n",
      "..                                                 ...             ...   \n",
      "403  ['fiction''young-adult''fantasyparanormal''chi...               9   \n",
      "475  ['non-fiction''historyhistorical fictionbiogra...               0   \n",
      "531  ['young-adult''fiction''fantasyparanormal''rom...               0   \n",
      "678  ['comicsgraphic''fiction''fantasyparanormal''m...               0   \n",
      "804  ['young-adult''mysterythrillercrime''fiction''...               0   \n",
      "\n",
      "     genre_comics  genre_fantasy  genre_fiction  genre_history  genre_mystery  \\\n",
      "0               0              2              9              1              2   \n",
      "1               2              0              9              1              0   \n",
      "2               2              0              9              1              2   \n",
      "3               0              0              9              0              2   \n",
      "4               0              0              9              0              0   \n",
      "..            ...            ...            ...            ...            ...   \n",
      "403             0              2              9              0              0   \n",
      "475             2              0              0              1              0   \n",
      "531             0              2              9              0              0   \n",
      "678             2              2              9              0              2   \n",
      "804             0              0              9              0              2   \n",
      "\n",
      "     genre_non-fiction  genre_poetry  genre_romance  genre_young-adult  \\\n",
      "0                    0             0              9                  9   \n",
      "1                   64             0              0                  9   \n",
      "2                   64             0              0                  9   \n",
      "3                    0             0              0                  0   \n",
      "4                    0             0              9                  9   \n",
      "..                 ...           ...            ...                ...   \n",
      "403                  0             0              0                  9   \n",
      "475                 64             0              0                  0   \n",
      "531                  0             0              9                  9   \n",
      "678                  0             0              0                  0   \n",
      "804                  0             0              9                  9   \n",
      "\n",
      "     genre_biography  genre_crime  genre_graphic  genre_historical fiction  \\\n",
      "0                  2            2              0                         1   \n",
      "1                  2            0              2                         1   \n",
      "2                  2            2              2                         1   \n",
      "3                  0            2              0                         0   \n",
      "4                  0            0              0                         0   \n",
      "..               ...          ...            ...                       ...   \n",
      "403                0            0              0                         0   \n",
      "475                2            0              2                         1   \n",
      "531                0            0              0                         0   \n",
      "678                0            2              2                         0   \n",
      "804                0            2              0                         0   \n",
      "\n",
      "     genre_paranormal  genre_thriller  \n",
      "0                   2               1  \n",
      "1                   0               0  \n",
      "2                   0               1  \n",
      "3                   0               1  \n",
      "4                   0               0  \n",
      "..                ...             ...  \n",
      "403                 2               0  \n",
      "475                 0               0  \n",
      "531                 2               0  \n",
      "678                 2               1  \n",
      "804                 0               1  \n",
      "\n",
      "[165 rows x 20 columns]>\n"
     ]
    }
   ],
   "source": [
    "#print(book_metadata.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_id_mapping_x      3        38        79        93       99        116  \\\n",
      "user_id_mapping                                                              \n",
      "0                  3.74569  4.00625  4.210938  4.245935  3.31016  4.231293   \n",
      "1                  3.74569  4.00625  4.210938  4.245935  3.31016  4.231293   \n",
      "3                  3.74569  4.00625  4.210938  4.245935  3.31016  4.231293   \n",
      "4                  3.74569  4.00625  4.210938  4.245935  3.31016  4.231293   \n",
      "7                  3.74569  4.00625  4.210938  4.245935  3.31016  4.231293   \n",
      "\n",
      "book_id_mapping_x       137       144       158       170  ...       813  \\\n",
      "user_id_mapping                                            ...             \n",
      "0                  4.205882  4.333333  4.361345  3.888112  ...  4.142857   \n",
      "1                  4.205882  4.333333  4.361345  3.888112  ...  4.142857   \n",
      "3                  4.205882  4.333333  4.361345  3.888112  ...  4.142857   \n",
      "4                  4.205882  4.333333  4.361345  3.888112  ...  4.142857   \n",
      "7                  4.205882  4.333333  4.361345  3.888112  ...  4.142857   \n",
      "\n",
      "book_id_mapping_x       836       846       847       855       868       873  \\\n",
      "user_id_mapping                                                                 \n",
      "0                  4.261628  4.145833  3.000000  3.568421  4.174603  4.653846   \n",
      "1                  4.261628  4.145833  3.648045  3.568421  4.174603  4.653846   \n",
      "3                  4.261628  4.000000  3.648045  3.568421  4.174603  4.653846   \n",
      "4                  4.261628  4.145833  3.648045  3.568421  4.174603  4.653846   \n",
      "7                  4.261628  4.145833  3.648045  3.568421  4.174603  4.653846   \n",
      "\n",
      "book_id_mapping_x       878       882       914  \n",
      "user_id_mapping                                  \n",
      "0                  3.833333  3.990654  4.064516  \n",
      "1                  3.833333  3.990654  4.064516  \n",
      "3                  3.833333  3.990654  4.064516  \n",
      "4                  3.833333  3.990654  4.064516  \n",
      "7                  3.833333  3.990654  4.064516  \n",
      "\n",
      "[5 rows x 96 columns]\n",
      "   book_id_mapping_x  num_pages  ratings_count  \\\n",
      "0              413.0     3520.0      1160907.0   \n",
      "1              753.0     1224.0       955760.0   \n",
      "2              847.0     2208.0      3771432.0   \n",
      "3              268.0     1016.0       833576.0   \n",
      "4              846.0      849.0       295314.0   \n",
      "\n",
      "                                         genre_split  genre_children  \\\n",
      "0  ['fantasyparanormal''romance''fiction''history...               0   \n",
      "1  ['comicsgraphic''non-fiction''historyhistorica...               0   \n",
      "2  ['non-fiction''historyhistorical fictionbiogra...               9   \n",
      "3                  ['mysterythrillercrime''fiction']               0   \n",
      "4                  ['romance''young-adult''fiction']               0   \n",
      "\n",
      "   genre_comics  genre_fantasy  genre_fiction  genre_history  genre_mystery  \\\n",
      "0             0              2              9              1              2   \n",
      "1             2              0              9              1              0   \n",
      "2             2              0              9              1              2   \n",
      "3             0              0              9              0              2   \n",
      "4             0              0              9              0              0   \n",
      "\n",
      "   genre_non-fiction  genre_poetry  genre_romance  genre_young-adult  \\\n",
      "0                  0             0              9                  9   \n",
      "1                 64             0              0                  9   \n",
      "2                 64             0              0                  9   \n",
      "3                  0             0              0                  0   \n",
      "4                  0             0              9                  9   \n",
      "\n",
      "   genre_biography  genre_crime  genre_graphic  genre_historical fiction  \\\n",
      "0                2            2              0                         1   \n",
      "1                2            0              2                         1   \n",
      "2                2            2              2                         1   \n",
      "3                0            2              0                         0   \n",
      "4                0            0              0                         0   \n",
      "\n",
      "   genre_paranormal  genre_thriller  \n",
      "0                 2               1  \n",
      "1                 0               0  \n",
      "2                 0               1  \n",
      "3                 0               1  \n",
      "4                 0               0  \n"
     ]
    }
   ],
   "source": [
    "# Example DataFrames to check their structure\n",
    "#print(user_item_matrix_imputed.head())\n",
    "#print(book_metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that user_item_matrix_imputed is indexed by book IDs\n",
    "#user_item_matrix_imputed = user_item_matrix_imputed.T  # Transpose to get book IDs as index\n",
    "\n",
    "# Merge metadata with user-item matrix\n",
    "#user_item_with_metadata = user_item_matrix_imputed.join(\n",
    "    book_metadata.set_index('book_id_mapping_x'),\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Transpose back to the original format\n",
    "#user_item_with_metadata = user_item_with_metadata.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  3.0,  38.0,  79.0,  93.0,  99.0, 116.0, 137.0, 144.0, 158.0, 170.0,\n",
      "       186.0, 205.0, 217.0, 220.0, 221.0, 224.0, 230.0, 231.0, 235.0, 248.0,\n",
      "       260.0, 262.0, 268.0, 271.0, 272.0, 286.0, 293.0, 299.0, 313.0, 315.0,\n",
      "       318.0, 339.0, 348.0, 350.0, 406.0, 410.0, 411.0, 413.0, 419.0, 421.0,\n",
      "       436.0, 437.0, 440.0, 450.0, 456.0, 479.0, 481.0, 490.0, 497.0, 505.0,\n",
      "       513.0, 524.0, 528.0, 530.0, 543.0, 544.0, 553.0, 562.0, 569.0, 571.0,\n",
      "       578.0, 580.0, 589.0, 594.0, 601.0, 626.0, 627.0, 636.0, 651.0, 674.0,\n",
      "       680.0, 691.0, 693.0, 697.0, 707.0, 719.0, 753.0, 765.0, 767.0, 769.0,\n",
      "       779.0, 780.0, 790.0, 802.0, 810.0, 812.0, 813.0, 836.0, 846.0, 847.0,\n",
      "       855.0, 868.0, 873.0, 878.0, 882.0, 914.0],\n",
      "      dtype='float64', name='book_id_mapping_x')\n"
     ]
    }
   ],
   "source": [
    "#print(user_item_with_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  3.0,  38.0,  79.0,  93.0,  99.0, 116.0, 137.0, 144.0, 158.0, 170.0,\n",
      "       186.0, 205.0, 217.0, 220.0, 221.0, 224.0, 230.0, 231.0, 235.0, 248.0,\n",
      "       260.0, 262.0, 268.0, 271.0, 272.0, 286.0, 293.0, 299.0, 313.0, 315.0,\n",
      "       318.0, 339.0, 348.0, 350.0, 406.0, 410.0, 411.0, 413.0, 419.0, 421.0,\n",
      "       436.0, 437.0, 440.0, 450.0, 456.0, 479.0, 481.0, 490.0, 497.0, 505.0,\n",
      "       513.0, 524.0, 528.0, 530.0, 543.0, 544.0, 553.0, 562.0, 569.0, 571.0,\n",
      "       578.0, 580.0, 589.0, 594.0, 601.0, 626.0, 627.0, 636.0, 651.0, 674.0,\n",
      "       680.0, 691.0, 693.0, 697.0, 707.0, 719.0, 753.0, 765.0, 767.0, 769.0,\n",
      "       779.0, 780.0, 790.0, 802.0, 810.0, 812.0, 813.0, 836.0, 846.0, 847.0,\n",
      "       855.0, 868.0, 873.0, 878.0, 882.0, 914.0],\n",
      "      dtype='float64', name='book_id_mapping_x')\n"
     ]
    }
   ],
   "source": [
    "# Transpose user_item_matrix_imputed for merging, then transpose back\n",
    "#user_item_with_metadata = user_item_matrix_imputed.T.join(book_metadata.set_index('book_id_mapping_x')).T\n",
    "#print(user_item_with_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Actual Rating' is correctly referenced\n",
    "user_ratings = user_item_matrix_imputed  # This contains the actual ratings per user and book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([    0,     1,     3,     4,     7,     9,    11,    12,    21,    33,\n",
      "       ...\n",
      "       83482, 83532, 83533, 83695, 83815, 83971, 84075, 84107, 84228, 84290],\n",
      "      dtype='int64', name='user_id_mapping', length=15039)\n"
     ]
    }
   ],
   "source": [
    "print(user_item_with_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([    0,     1,     3,     4,     7,     9,    11,    12,    21,    33,\n",
      "       ...\n",
      "       83482, 83532, 83533, 83695, 83815, 83971, 84075, 84107, 84228, 84290],\n",
      "      dtype='int64', name='user_id_mapping', length=15039)\n"
     ]
    }
   ],
   "source": [
    "print(user_item_with_metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'num_pages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:175\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_pages'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Multiply each user's rating by book metadata like num_pages and ratings_count\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_pages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratings_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m genre_columns:\n\u001b[0;32m----> 3\u001b[0m     user_item_with_metadata[col] \u001b[38;5;241m=\u001b[39m user_ratings \u001b[38;5;241m*\u001b[39m user_item_with_metadata[col]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# If necessary, you can fill NaNs resulting from the multiplication\u001b[39;00m\n\u001b[1;32m      6\u001b[0m user_item_with_metadata\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_pages'"
     ]
    }
   ],
   "source": [
    "# Multiply each user's rating by book metadata like num_pages and ratings_count\n",
    "for col in ['num_pages', 'ratings_count'] + genre_columns:\n",
    "    user_item_with_metadata[col] = user_ratings * user_item_with_metadata[col].T\n",
    "\n",
    "# If necessary, you can fill NaNs resulting from the multiplication\n",
    "user_item_with_metadata.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Actual Rating'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Actual Rating'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# now create the vector for each user by combining book ratings and book metadata\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Multiply ratings by book metadata (if genre is one-hot encoded)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_pages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratings_count\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     user_item_with_metadata[col] \u001b[38;5;241m=\u001b[39m user_item_with_metadata\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Rating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m user_item_with_metadata[col]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Drop book metadata columns if you want to keep just ratings, or keep them for enriched vectors\u001b[39;00m\n\u001b[1;32m      7\u001b[0m user_vectors \u001b[38;5;241m=\u001b[39m user_item_with_metadata\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_pages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratings_count\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mxs(label, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:4301\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4299\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4301\u001b[0m     loc \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4304\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Actual Rating'"
     ]
    }
   ],
   "source": [
    "# now create the vector for each user by combining book ratings and book metadata\n",
    "# Multiply ratings by book metadata (if genre is one-hot encoded)\n",
    "for col in ['num_pages', 'ratings_count']:\n",
    "    user_item_with_metadata[col] = user_item_with_metadata.loc['Actual Rating'] * user_item_with_metadata[col]\n",
    "\n",
    "# Drop book metadata columns if you want to keep just ratings, or keep them for enriched vectors\n",
    "user_vectors = user_item_with_metadata.drop(['num_pages', 'ratings_count'], axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: dimensionality reduction - do we need this?\n",
    "pca = PCA(n_components=2)  # Adjust the number of components based on your data\n",
    "user_vectors_pca = pca.fit_transform(user_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally the clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  # Adjust the number of clusters\n",
    "user_clusters = kmeans.fit_predict(user_vectors_pca)\n",
    "\n",
    "# Add the cluster labels to the user vectors\n",
    "user_vectors['Cluster'] = user_clusters\n",
    "\n",
    "#check the results by printing it\n",
    "print(user_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
